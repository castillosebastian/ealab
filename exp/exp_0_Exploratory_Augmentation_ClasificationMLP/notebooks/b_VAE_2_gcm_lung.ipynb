{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "polars.config.Config"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, f1_score, multilabel_confusion_matrix\n",
        "from scipy.io import arff\n",
        "\n",
        "# Set the device for PyTorch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configure Polars\n",
        "pl.Config.set_tbl_rows(-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAE implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Source**:\n",
        "- https://github.com/clementchadebec/benchmark_VAE\n",
        "- https://github.com/Victarry/Image-Generation-models/blob/main/src/models/vae.py    \n",
        "- https://github.com/yakhyo/pytorch-tutorials/blob/23d4086486482eb13fae05a87ef93a1e0df8b0ff/tutorials/03-intermediate/05-var-auto-encode/main.py\n",
        "\n",
        "Others:\n",
        "\n",
        "- https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/VAE.ipynb\n",
        "- https://github.com/siddharth17196/Variational-Autoencoders/blob/master/autoencoder.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read from directory\n",
        "tra, trameta = arff.loadarff('../../data/GCM_Training.arff')\n",
        "tst, tstmeta = arff.loadarff('../../data/GCM_Test.arff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pl.from_numpy(tra).to_numpy()\n",
        "test = pl.from_numpy(tst).to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter lung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "lung_train = train[train[:, -1] == b'Lung']\n",
        "lung_test = test[test[:, -1] == b'Lung']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 16064)\n",
            "(3, 16064)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(lung_train.shape), print(lung_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = lung_train\n",
        "test = lung_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{b'Lung': 0}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = [binary_str.decode('utf-8') for binary_str in set(train[:,-1])]\n",
        "# Create a mapping from category to integer\n",
        "target_mapping = {category.encode(): index for index, category in enumerate(categories)}\n",
        "target_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map binary targets to numerical values\n",
        "numerical_targets_train = np.array([target_mapping.get(x[-1], x) for x in train])\n",
        "numerical_targets_test = np.array([target_mapping.get(x[-1], x) for x in test])\n",
        "train[:, -1] = numerical_targets_train\n",
        "test[:, -1] = numerical_targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-47.0, -171.0, -284.0, ..., 89.0, -1324.0, -70.0], dtype=object),\n",
              " array([-94.0, -256.0, -358.0, ..., 34.0, -1233.0, -47.0], dtype=object))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = train[:,:-1]\n",
        "test = test[:,:-1]\n",
        "train[0], test[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the array to float32\n",
        "train = train.astype(np.float32)\n",
        "test = test.astype(np.float32)\n",
        "\n",
        "# Convert to a PyTorch tensor\n",
        "train = torch.from_numpy(train)\n",
        "test =  torch.from_numpy(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_data(data):\n",
        "    min_val = torch.min(data)\n",
        "    max_val = torch.max(data)\n",
        "    normalized_data = (data - min_val) / (max_val - min_val)\n",
        "    return normalized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_norm = normalize_data(train)\n",
        "test_norm = normalize_data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 16063])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_norm[0]\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create train and test dataloaders\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(dataset=train_norm, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_norm, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Variational Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Ezw2ckDTmSJw"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=16063, hidden_dim=400, latent_dim=200, device=device):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, latent_dim),\n",
        "            nn.LeakyReLU(0.2)\n",
        "            )\n",
        "\n",
        "        # latent mean and variance\n",
        "        self.mean_layer = nn.Linear(latent_dim, 2)\n",
        "        self.logvar_layer = nn.Linear(latent_dim, 2)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, latent_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterization(self, mean, var):\n",
        "        epsilon = torch.randn_like(var).to(device)\n",
        "        z = mean + var*epsilon\n",
        "        return z\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterization(mean, logvar)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, mean, log_var\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, log_var = self.encode(x)\n",
        "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, mean, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wOuxwnnVnbBJ"
      },
      "outputs": [],
      "source": [
        "model = VAE(input_dim=16063).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RlwQdnotney0"
      },
      "outputs": [],
      "source": [
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
        "    return reproduction_loss + KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainVAE(model, optimizer, epochs, device, x_dim=16063):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        overall_loss = 0\n",
        "        for batch_idx, x in enumerate(train_loader):\n",
        "            \n",
        "            x = x.view(x.size(0), x_dim).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x_hat, mean, log_var = model(x)\n",
        "            loss = loss_function(x, x_hat, mean, log_var)\n",
        "            \n",
        "            overall_loss += loss.item()\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*batch_size))\n",
        "    return overall_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([4, 16063])\n"
          ]
        }
      ],
      "source": [
        "# Get the first batch of data\n",
        "first_batch = next(iter(train_loader))\n",
        "\n",
        "# Print the type and length/shape of the first batch\n",
        "print(type(first_batch))\n",
        "if isinstance(first_batch, (list, tuple)):\n",
        "    print([type(item) for item in first_batch])\n",
        "    print([item.shape if hasattr(item, 'shape') else len(item) for item in first_batch])\n",
        "else:\n",
        "    print(first_batch.shape if hasattr(first_batch, 'shape') else len(first_batch))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-7CIF3GYUA",
        "outputId": "7e11a45f-d70f-428b-e93f-f32c2f464f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tEpoch 1 \tAverage Loss:  16614.05078125\n",
            "\tEpoch 2 \tAverage Loss:  16620.873046875\n",
            "\tEpoch 3 \tAverage Loss:  16615.5419921875\n",
            "\tEpoch 4 \tAverage Loss:  16613.958984375\n",
            "\tEpoch 5 \tAverage Loss:  16616.109375\n",
            "\tEpoch 6 \tAverage Loss:  16616.91796875\n",
            "\tEpoch 7 \tAverage Loss:  16615.4169921875\n",
            "\tEpoch 8 \tAverage Loss:  16610.0166015625\n",
            "\tEpoch 9 \tAverage Loss:  16606.78515625\n",
            "\tEpoch 10 \tAverage Loss:  16608.5146484375\n",
            "\tEpoch 11 \tAverage Loss:  16608.4140625\n",
            "\tEpoch 12 \tAverage Loss:  16610.7138671875\n",
            "\tEpoch 13 \tAverage Loss:  16613.06640625\n",
            "\tEpoch 14 \tAverage Loss:  16609.8251953125\n",
            "\tEpoch 15 \tAverage Loss:  16607.193359375\n",
            "\tEpoch 16 \tAverage Loss:  16606.7578125\n",
            "\tEpoch 17 \tAverage Loss:  16608.5908203125\n",
            "\tEpoch 18 \tAverage Loss:  16606.73046875\n",
            "\tEpoch 19 \tAverage Loss:  16608.6904296875\n",
            "\tEpoch 20 \tAverage Loss:  16605.1796875\n",
            "\tEpoch 21 \tAverage Loss:  16607.5048828125\n",
            "\tEpoch 22 \tAverage Loss:  16604.99609375\n",
            "\tEpoch 23 \tAverage Loss:  16606.3203125\n",
            "\tEpoch 24 \tAverage Loss:  16606.5341796875\n",
            "\tEpoch 25 \tAverage Loss:  16604.9755859375\n",
            "\tEpoch 26 \tAverage Loss:  16605.56640625\n",
            "\tEpoch 27 \tAverage Loss:  16607.4013671875\n",
            "\tEpoch 28 \tAverage Loss:  16606.57421875\n",
            "\tEpoch 29 \tAverage Loss:  16603.568359375\n",
            "\tEpoch 30 \tAverage Loss:  16604.681640625\n",
            "\tEpoch 31 \tAverage Loss:  16604.9111328125\n",
            "\tEpoch 32 \tAverage Loss:  16608.91015625\n",
            "\tEpoch 33 \tAverage Loss:  16607.244140625\n",
            "\tEpoch 34 \tAverage Loss:  16604.80078125\n",
            "\tEpoch 35 \tAverage Loss:  16605.0947265625\n",
            "\tEpoch 36 \tAverage Loss:  16607.33203125\n",
            "\tEpoch 37 \tAverage Loss:  16604.62109375\n",
            "\tEpoch 38 \tAverage Loss:  16607.6484375\n",
            "\tEpoch 39 \tAverage Loss:  16605.9765625\n",
            "\tEpoch 40 \tAverage Loss:  16605.01953125\n",
            "\tEpoch 41 \tAverage Loss:  16604.693359375\n",
            "\tEpoch 42 \tAverage Loss:  16604.5458984375\n",
            "\tEpoch 43 \tAverage Loss:  16603.1669921875\n",
            "\tEpoch 44 \tAverage Loss:  16603.2314453125\n",
            "\tEpoch 45 \tAverage Loss:  16604.79296875\n",
            "\tEpoch 46 \tAverage Loss:  16604.54296875\n",
            "\tEpoch 47 \tAverage Loss:  16603.603515625\n",
            "\tEpoch 48 \tAverage Loss:  16608.056640625\n",
            "\tEpoch 49 \tAverage Loss:  16602.6591796875\n",
            "\tEpoch 50 \tAverage Loss:  16602.0703125\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "66408.28125"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainVAE(model, optimizer, epochs=50, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_data(model, num_samples, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Sample from a standard normal distribution with shape [num_samples, 2]\n",
        "        z = torch.randn(num_samples, 2).to(device)  # Adjusted to match the decoder's input dimension\n",
        "        # Generate synthetic data\n",
        "        synthetic_data = model.decode(z)\n",
        "    return synthetic_data.cpu()\n",
        "\n",
        "# Example usage\n",
        "num_samples = 10  # Number of synthetic data points you want to generate\n",
        "synthetic_data = generate_synthetic_data(model, num_samples, device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 16063])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "synthetic_data.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.4541, 0.4503, 0.4479,  ..., 0.4558, 0.4298, 0.4513])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "synthetic_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = synthetic_data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.45411989092826843, 0.4502677917480469, 0.4478558897972107, ...,\n",
              "       0.4297598898410797, 0.4513128995895386, b'Lung'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_rows = data.shape[0]\n",
        "labels = np.full((num_rows, 1), b'Lung', dtype=object)\n",
        "\n",
        "# Combine the original array with the label column\n",
        "combined_data = np.column_stack((data, labels))\n",
        "\n",
        "combined_data[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('syn_lung.npy', combined_data)\n",
        "# lung = np.load('syn_lung.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save(model, 'vae_lung_model.pth') # save all model and parameters\n",
        "torch.save(model.state_dict(), 'vae_lung_model_state_dict.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model \n",
        "model = VAE(input_dim=16063, hidden_dim=400, latent_dim=200, device=device)\n",
        "model.load_state_dict(torch.load('vae_model_state_dict.pth'))\n",
        "model.to(device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
