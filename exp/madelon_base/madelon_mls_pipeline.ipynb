{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e058f67f",
   "metadata": {},
   "source": [
    "# Mandelon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e50b8",
   "metadata": {},
   "source": [
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bde6f",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- https://github.com/dstrodtman/madelon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36770985-f171-4897-8da7-6fdda5f3ed05",
   "metadata": {},
   "source": [
    "## Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd078ca-8a70-44fb-a1a5-b4c8c0a026af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from scipy.io import arff\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb75661",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra, trameta = arff.loadarff('/home/sebacastillo/ealab/data/madelon.trn.arff')\n",
    "tst, tstmeta = arff.loadarff('/home/sebacastillo/ealab/data/madelon.tst.arff')\n",
    "train = pl.DataFrame(tra)\n",
    "test =  pl.DataFrame(tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5bafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    train.with_columns(\n",
    "        pl.col('class').cast(pl.datatypes.Utf8)\n",
    "    )   \n",
    ")\n",
    "test = (\n",
    "    test.with_columns(\n",
    "        pl.col('class').cast(pl.datatypes.Utf8)\n",
    "    )   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6cf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.write_csv('train.csv', separator=',')\n",
    "#test.write_csv('test.csv', separator=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b809a9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>class</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;1&quot;</td><td>1000</td></tr><tr><td>&quot;-1&quot;</td><td>1000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬───────┐\n",
       "│ class ┆ count │\n",
       "│ ---   ┆ ---   │\n",
       "│ str   ┆ u32   │\n",
       "╞═══════╪═══════╡\n",
       "│ 1     ┆ 1000  │\n",
       "│ -1    ┆ 1000  │\n",
       "└───────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('class').agg(pl.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8fc82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 501)\n",
      "(600, 501)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape), print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c45474d1-fdd8-4f23-a516-28dc9bd6499d",
   "metadata": {},
   "source": [
    "# PARTICIONO LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5182035-78f5-43b2-b817-a21c2c4b804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = train\n",
    "TEST = test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40791c59-5d5f-4fa5-aa85-9fb6a6d5677e",
   "metadata": {},
   "source": [
    "# Normalizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1b167a-fa67-4a64-9c1a-2be96256c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN = TRAIN.to_numpy()\n",
    "TEST = TEST.to_numpy()\n",
    "\n",
    "X_train = TRAIN[:,:-1]\n",
    "y_train = TRAIN[:,-1]\n",
    "y_train = np.where(np.array(y_train) == '1', 1, 0).astype('int64')\n",
    "X_test = TEST[:,:-1]\n",
    "y_test = TEST[:,-1]\n",
    "y_test = np.where(np.array(y_test) == '1', 1, 0).astype('int64')\n",
    "\n",
    "#scaler.fit(X_TRAIN)\n",
    "#Xtrain = scaler.transform(X_TRAIN)\n",
    "#Xtest = scaler.transform(X_TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2ccff",
   "metadata": {},
   "source": [
    "# Pipeline MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8720f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e496e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
    "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
    "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
    "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
    "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
    "classifiers.update({\"MLP\": MLPClassifier()})\n",
    "classifiers.update({\"SVC\": SVC()})\n",
    "\n",
    "\n",
    "# Initiate parameter grid\n",
    "parameters = {}\n",
    "\n",
    "# Update dict with AdaBoost\n",
    "parameters.update({\"AdaBoost\": { \n",
    "                                \"classifier__estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
    "                                 }})\n",
    "\n",
    "# Update dict with Gradient Boosting\n",
    "parameters.update({\"Gradient Boosting\": { \n",
    "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                                        \"classifier__n_estimators\": [200],\n",
    "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
    "                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"classifier__subsample\": [0.8, 0.9, 1]\n",
    "                                         }})\n",
    "\n",
    "# Update dict with Extra Trees\n",
    "parameters.update({\"Extra Trees Ensemble\": { \n",
    "                                            \"classifier__n_estimators\": [200],\n",
    "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                            \"classifier__n_jobs\": [-1]\n",
    "                                             }})\n",
    "\n",
    "\n",
    "# Update dict with Random Forest Parameters\n",
    "parameters.update({\"Random Forest\": { \n",
    "                                    \"classifier__n_estimators\": [200],\n",
    "                                    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                    \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                    \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                    \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                    \"classifier__n_jobs\": [-1]\n",
    "                                     }})\n",
    "\n",
    "# Update dict with K Nearest Neighbors Classifier\n",
    "parameters.update({\"KNN\": { \n",
    "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
    "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
    "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "# Update dict with MLPClassifier\n",
    "parameters.update({\"MLP\": { \n",
    "                            \"classifier__hidden_layer_sizes\": [(5,5), (10,10), (5,5,5), (10,10,10)],\n",
    "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                            \"classifier__max_iter\": [1000, 2000],\n",
    "                            \"classifier__alpha\": list(10.0 ** -np.arange(1, 10)),\n",
    "                             }})\n",
    "parameters.update({\"SVC\": { \n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__gamma\": [\"auto\"],\n",
    "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
    "                             }})\n",
    "\n",
    "# Create dict of decision function labels\n",
    "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c694ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Tune and evaluate classifiers\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    # Print message to user\n",
    "    print(f\"Now tuning {classifier_label}.\")\n",
    "    \n",
    "    # Scale features via Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Define steps in pipeline\n",
    "    steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "      \n",
    "    # Define parameter grid\n",
    "    param_grid = parameters[classifier_label]\n",
    "    \n",
    "    # Initialize GridSearch object\n",
    "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "                      \n",
    "    # Fit gscv\n",
    "    gscv.fit(X_train, np.ravel(y_train))  \n",
    "    \n",
    "    # Get best parameters and score\n",
    "    best_params = gscv.best_params_\n",
    "    best_score = gscv.best_score_\n",
    "    \n",
    "    # Update classifier parameters and define new pipeline with tuned classifier\n",
    "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "    classifier.set_params(**tuned_params)\n",
    "            \n",
    "    # Make predictions\n",
    "    if classifier_label in DECISION_FUNCTIONS:\n",
    "        y_pred = gscv.decision_function(X_test)\n",
    "    else:\n",
    "        y_pred = gscv.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Evaluate model\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Save results\n",
    "    result = {\"Classifier\": gscv,\n",
    "              \"Best Parameters\": best_params,\n",
    "              \"Training AUC\": best_score,\n",
    "              \"Test AUC\": auc}\n",
    "    \n",
    "    results.update({classifier_label: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores = {\n",
    "              \"Classifier\": [],\n",
    "              \"AUC\": [],\n",
    "              \"AUC Type\": []\n",
    "              }\n",
    "\n",
    "# Get AUC scores into dictionary\n",
    "for classifier_label in results:\n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Training AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Training\"] + auc_scores[\"AUC Type\"]})\n",
    "    \n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Test AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Test\"] + auc_scores[\"AUC Type\"]})\n",
    "\n",
    "# Dictionary to PandasDataFrame\n",
    "auc_scores = pd.DataFrame(auc_scores)\n",
    "\n",
    "# Convert DataFrame to string\n",
    "text_representation = auc_scores.to_string()\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"auc_scores.txt\", \"w\") as file:\n",
    "    file.write(text_representation)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "    \n",
    "# Colors\n",
    "training_color = sns.color_palette(\"RdYlBu\", 10)[1]\n",
    "test_color = sns.color_palette(\"RdYlBu\", 10)[-2]\n",
    "colors = [training_color, test_color]\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "sns.barplot(x=\"AUC\", y=\"Classifier\", hue=\"AUC Type\", palette = colors,\n",
    "            data=auc_scores)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"AUC Scores.png\", dpi = 1080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
