{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Get the root directory of your project (the directory containing 'src' and 'plugins')\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "data_dir = \"/home/sebacastillo/ealab/data/\"\n",
    "exp_dir = \"/home/sebacastillo/ealab/exp/exp_9_VAE_CVAE_ArchitectureDesign/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root=data_dir, train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebacastillo/.ealab/lib/python3.9/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim, c_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim + c_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim + c_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "    \n",
    "    def encoder(self, x, c):\n",
    "        concat_input = torch.cat([x, c], 1)\n",
    "        h = F.relu(self.fc1(concat_input))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add(mu) # return z sample\n",
    "    \n",
    "    def decoder(self, z, c):\n",
    "        concat_input = torch.cat([z, c], 1)\n",
    "        h = F.relu(self.fc4(concat_input))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784), c)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z, c), mu, log_var\n",
    "\n",
    "# build model\n",
    "cond_dim = train_loader.dataset.train_labels.unique().size(0)\n",
    "cvae = CVAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2, c_dim=cond_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE(\n",
       "  (fc1): Linear(in_features=794, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=12, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cvae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# one-hot encoding\n",
    "def one_hot(labels, class_size): \n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return Variable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    cvae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, cond) in enumerate(train_loader):\n",
    "        data, cond = data, one_hot(cond, cond_dim)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = cvae(data, cond)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    cvae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, cond in test_loader:\n",
    "            data, cond = data, one_hot(cond, cond_dim)\n",
    "            recon, mu, log_var = cvae(data, cond)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.072344\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 173.242422\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 165.536113\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 154.799922\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 152.220391\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 142.667285\n",
      "====> Epoch: 1 Average loss: 164.1120\n",
      "====> Test set loss: 142.0621\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 146.131270\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 144.932852\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 137.513926\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 134.806133\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 129.121055\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 134.642607\n",
      "====> Epoch: 2 Average loss: 138.8045\n",
      "====> Test set loss: 136.4461\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 133.437529\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 141.232275\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 132.995977\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 133.285498\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 133.375039\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 133.289541\n",
      "====> Epoch: 3 Average loss: 135.1127\n",
      "====> Test set loss: 134.3041\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 132.303730\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 129.839854\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 139.211279\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 124.369873\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 133.791611\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 127.039814\n",
      "====> Epoch: 4 Average loss: 133.3484\n",
      "====> Test set loss: 132.8393\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 127.891484\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 131.049355\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 138.064766\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 136.025361\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 135.224102\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 124.111104\n",
      "====> Epoch: 5 Average loss: 132.2612\n",
      "====> Test set loss: 132.6608\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 127.986699\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 130.894609\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 136.470596\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 133.253301\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 130.106162\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 129.908232\n",
      "====> Epoch: 6 Average loss: 131.5226\n",
      "====> Test set loss: 131.4962\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 127.734824\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 131.880283\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 137.548262\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 131.097246\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 132.903359\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 120.435449\n",
      "====> Epoch: 7 Average loss: 130.8926\n",
      "====> Test set loss: 131.2544\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 130.261309\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 126.678779\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 130.412725\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 129.343613\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 128.661641\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 125.373594\n",
      "====> Epoch: 8 Average loss: 130.4309\n",
      "====> Test set loss: 130.8721\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 134.271377\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 126.360664\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 136.407656\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 131.909941\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 128.170303\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 119.364453\n",
      "====> Epoch: 9 Average loss: 130.0021\n",
      "====> Test set loss: 130.4881\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 136.562344\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 132.507676\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 126.056240\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 126.326846\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 124.862744\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 122.375420\n",
      "====> Epoch: 10 Average loss: 129.6675\n",
      "====> Test set loss: 130.2975\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 133.140732\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 123.529551\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 130.440469\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 133.988447\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 133.171670\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 126.876826\n",
      "====> Epoch: 11 Average loss: 129.2842\n",
      "====> Test set loss: 129.9479\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 131.330293\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 134.492129\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 129.263545\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 133.470283\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 130.207158\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 125.527549\n",
      "====> Epoch: 12 Average loss: 129.0194\n",
      "====> Test set loss: 129.6733\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 131.140098\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 130.124844\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 132.638828\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 127.692334\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 136.833496\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 126.828867\n",
      "====> Epoch: 13 Average loss: 128.7147\n",
      "====> Test set loss: 129.4229\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 123.913125\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 114.670703\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 132.802373\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 130.311309\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 129.080615\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 132.259893\n",
      "====> Epoch: 14 Average loss: 128.4338\n",
      "====> Test set loss: 129.3987\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 130.197217\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 126.966104\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 128.168574\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 128.362920\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 134.294805\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 127.069355\n",
      "====> Epoch: 15 Average loss: 128.1661\n",
      "====> Test set loss: 129.2561\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 139.333750\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 122.778193\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 118.819834\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 131.147549\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 128.256240\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 129.505361\n",
      "====> Epoch: 16 Average loss: 127.8680\n",
      "====> Test set loss: 129.1110\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 130.672588\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 129.312305\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 136.731680\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 129.944434\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 134.194385\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 132.296934\n",
      "====> Epoch: 17 Average loss: 127.6950\n",
      "====> Test set loss: 128.9879\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 125.139014\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 118.029570\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 123.187402\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 123.077891\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 120.350410\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 128.109590\n",
      "====> Epoch: 18 Average loss: 127.5102\n",
      "====> Test set loss: 128.7882\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 120.582295\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 128.431348\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 134.944980\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 125.456240\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 134.880889\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 124.626211\n",
      "====> Epoch: 19 Average loss: 127.1780\n",
      "====> Test set loss: 128.6444\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 137.759766\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 120.356348\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 128.275625\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 131.511445\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 133.145303\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 130.802842\n",
      "====> Epoch: 20 Average loss: 126.9698\n",
      "====> Test set loss: 128.6206\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 131.121230\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 127.924727\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 128.372451\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 126.836123\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 123.377275\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 124.895293\n",
      "====> Epoch: 21 Average loss: 126.8090\n",
      "====> Test set loss: 128.6299\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 130.175137\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 128.436660\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 121.571152\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 125.223135\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 124.694717\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 127.657520\n",
      "====> Epoch: 22 Average loss: 126.5652\n",
      "====> Test set loss: 128.6503\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 120.017373\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 125.370449\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 121.173848\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 128.224541\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 126.540566\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 127.383906\n",
      "====> Epoch: 23 Average loss: 126.3692\n",
      "====> Test set loss: 128.3673\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 120.892441\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 127.658535\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 118.870918\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 129.327510\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 125.662969\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 120.623672\n",
      "====> Epoch: 24 Average loss: 126.2120\n",
      "====> Test set loss: 128.2854\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 132.798682\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 125.248711\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 127.663047\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 123.700771\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 132.963730\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 135.213174\n",
      "====> Epoch: 25 Average loss: 126.0126\n",
      "====> Test set loss: 128.1285\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 121.853770\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 134.281621\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 118.525146\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 128.212744\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 125.906924\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 126.254346\n",
      "====> Epoch: 26 Average loss: 125.8554\n",
      "====> Test set loss: 127.9887\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 122.287744\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 136.602871\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 131.530342\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 128.839980\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 133.564736\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 123.807139\n",
      "====> Epoch: 27 Average loss: 125.7145\n",
      "====> Test set loss: 128.0934\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 124.679141\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 123.279014\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 123.062139\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 124.038750\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 122.506621\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 129.302695\n",
      "====> Epoch: 28 Average loss: 125.4701\n",
      "====> Test set loss: 127.8892\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 124.051230\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 121.028770\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 121.299170\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 117.038096\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 127.819346\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 123.328926\n",
      "====> Epoch: 29 Average loss: 125.4238\n",
      "====> Test set loss: 127.7825\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 125.194219\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 122.734561\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 122.835547\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 125.186045\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 124.594648\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 129.090635\n",
      "====> Epoch: 30 Average loss: 125.2253\n",
      "====> Test set loss: 127.8697\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 120.044404\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 126.291631\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 117.415732\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 124.411826\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 116.187197\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 128.028242\n",
      "====> Epoch: 31 Average loss: 125.1314\n",
      "====> Test set loss: 127.7437\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 133.064453\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 129.526621\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 123.666230\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 127.010459\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 124.938555\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 119.624463\n",
      "====> Epoch: 32 Average loss: 124.9352\n",
      "====> Test set loss: 127.7280\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 123.650449\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 118.655879\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 131.024473\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 124.709795\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 126.656494\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 124.450400\n",
      "====> Epoch: 33 Average loss: 124.8965\n",
      "====> Test set loss: 127.7083\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 118.698076\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 125.417969\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 131.881055\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 129.386016\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 133.923350\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 125.980186\n",
      "====> Epoch: 34 Average loss: 124.7037\n",
      "====> Test set loss: 127.5249\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 121.308047\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 120.820186\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 122.651338\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 129.631387\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 119.870918\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 118.947607\n",
      "====> Epoch: 35 Average loss: 124.6707\n",
      "====> Test set loss: 127.5090\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 127.058994\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 127.719063\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 129.888281\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 120.691221\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 125.029336\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 123.201289\n",
      "====> Epoch: 36 Average loss: 124.4925\n",
      "====> Test set loss: 127.7568\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 125.922637\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 126.516416\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 118.149102\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 121.348047\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 124.478311\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 123.350381\n",
      "====> Epoch: 37 Average loss: 124.3207\n",
      "====> Test set loss: 127.4556\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 128.520215\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 120.850859\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 124.725605\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 121.845996\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 125.222852\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 120.496973\n",
      "====> Epoch: 38 Average loss: 124.2823\n",
      "====> Test set loss: 127.4561\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 124.513604\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 131.752070\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 133.628525\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 121.823115\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 120.918955\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 118.485391\n",
      "====> Epoch: 39 Average loss: 124.1311\n",
      "====> Test set loss: 127.7317\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 129.698418\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 126.237852\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 120.106348\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 122.942236\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 124.211367\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 130.276406\n",
      "====> Epoch: 40 Average loss: 123.9918\n",
      "====> Test set loss: 127.4764\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 121.940313\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 117.756338\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 121.905957\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 122.342256\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 125.240176\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 128.431826\n",
      "====> Epoch: 41 Average loss: 123.9709\n",
      "====> Test set loss: 127.5486\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 126.805586\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 119.910645\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 119.346055\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 122.668730\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 119.469717\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 128.188223\n",
      "====> Epoch: 42 Average loss: 123.8422\n",
      "====> Test set loss: 127.2889\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 121.019561\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 125.562461\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 126.177295\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 116.435771\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 119.923135\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 123.112314\n",
      "====> Epoch: 43 Average loss: 123.6687\n",
      "====> Test set loss: 127.4653\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 115.202471\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 122.538711\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 130.755996\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 127.556094\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 122.590977\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 122.970693\n",
      "====> Epoch: 44 Average loss: 123.5814\n",
      "====> Test set loss: 127.3021\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 118.736084\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 121.532656\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 128.469424\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 124.399141\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 129.089629\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 130.564980\n",
      "====> Epoch: 45 Average loss: 123.4714\n",
      "====> Test set loss: 127.2477\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 120.184785\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 124.842705\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 116.937930\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 125.659111\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 125.635439\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 118.667930\n",
      "====> Epoch: 46 Average loss: 123.3620\n",
      "====> Test set loss: 127.5807\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 119.179619\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 128.749395\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 120.910313\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 123.197158\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 128.647236\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 123.858584\n",
      "====> Epoch: 47 Average loss: 123.4286\n",
      "====> Test set loss: 127.5027\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 131.244922\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 118.584824\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 118.915957\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 127.545078\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 122.322412\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 127.554307\n",
      "====> Epoch: 48 Average loss: 123.2800\n",
      "====> Test set loss: 127.4051\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 125.222393\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 128.670459\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 126.096611\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 119.022529\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 123.766270\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 127.668418\n",
      "====> Epoch: 49 Average loss: 123.1635\n",
      "====> Test set loss: 127.2726\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 123.762148\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 115.918682\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 116.920918\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 117.985566\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 122.858477\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 122.479570\n",
      "====> Epoch: 50 Average loss: 123.2753\n",
      "====> Test set loss: 128.0888\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lyeoni\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(10, 2)\n",
    "    c = torch.eye(10)\n",
    "\n",
    "    sample = cvae.decoder(z, c)\n",
    "    save_image(sample.view(10, 1, 28, 28), exp_dir + '/sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
